{"cells":[{"cell_type":"markdown","metadata":{"id":"ZgVht93dkSFy"},"source":["# Load Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G7Tzjvz1kSF3","outputId":"317e9bd5-d63e-43c4-b06c-5179f32ac265"},"outputs":[{"name":"stdout","output_type":"stream","text":["   TransactionID  CustomerID  TransactionAmount TransactionDate  \\\n","0              1           1         130.221277      2022-01-01   \n","1              1           1         130.221277      2022-01-01   \n","2              1           1         130.221277      2022-01-01   \n","3              1           1         130.221277      2022-01-01   \n","4              1           1         130.221277      2022-01-01   \n","\n","  MerchantCategory  Age  Income Occupation  Gender  CampaignID CampaignDate  \\\n","0           Dining   38   75034     Doctor  Female           1   2022-01-01   \n","1           Dining   38   75034     Doctor  Female           2   2022-01-02   \n","2           Dining   38   75034     Doctor  Female           3   2022-01-03   \n","3           Dining   38   75034     Doctor  Female           4   2022-01-04   \n","4           Dining   38   75034     Doctor  Female           5   2022-01-05   \n","\n","   CampaignResponse  \n","0                 0  \n","1                 1  \n","2                 1  \n","3                 1  \n","4                 1  \n"]}],"source":["# Standard libraries\n","import numpy as np\n","import pandas as pd\n","\n","# Load the data\n","demographics = pd.read_csv('https://storage.googleapis.com/datalynn-datasets/Interview_Challenge/Amex/Amex_Marketing_Strategies/demographics.csv')\n","transactions = pd.read_csv('https://storage.googleapis.com/datalynn-datasets/Interview_Challenge/Amex/Amex_Marketing_Strategies/transactions.csv')\n","campaigns = pd.read_csv('https://storage.googleapis.com/datalynn-datasets/Interview_Challenge/Amex/Amex_Marketing_Strategies/campaigns.csv')\n","transactions['TransactionDate'] = pd.to_datetime(transactions['TransactionDate'])\n","campaigns['CampaignDate'] = pd.to_datetime(campaigns['CampaignDate'])\n","\n","# Merge the data\n","data = pd.merge(transactions, demographics, on='CustomerID')\n","data = pd.merge(data, campaigns, on='CustomerID')\n","\n","# Let's have a quick look at the data\n","print(data.head())"]},{"cell_type":"markdown","metadata":{"id":"fdTxo1dHkSF6"},"source":["# Data Manipulation\n","**Q1** As you can see, our dataset contains information on different merchant categories. However, the categorization is inconsistent across different entries. How would you standardize these categories?"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":163,"status":"ok","timestamp":1687979312688,"user":{"displayName":"Zhuchen Han (Shawn)","userId":"13195238100708308958"},"user_tz":240},"id":"ppL5dYfIqyNr","outputId":"222e6d92-79d3-4bb7-eaf8-bbb85c2b12a8"},"outputs":[{"name":"stdout","output_type":"stream","text":["['dining' 'clothing' 'entertainment' 'grocery' 'electronics']\n"]}],"source":["# Standardize merchant categories\n","data['MerchantCategory'] = data['MerchantCategory'].str.lower().str.strip()\n","\n","# Print the unique categories to verify\n","print(data['MerchantCategory'].unique())\n","\n"]},{"cell_type":"markdown","metadata":{"id":"2QIOQIue00RO"},"source":["**Q2** For certain transactions, you might notice some anomalies such as negative transaction amounts or transactions that take place in the future. Can you devise a strategy to identify and handle these outliers?"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":626,"status":"ok","timestamp":1687979314600,"user":{"displayName":"Zhuchen Han (Shawn)","userId":"13195238100708308958"},"user_tz":240},"id":"87sLgyw9q2Hp","outputId":"9bedefb9-65ed-4be6-edfe-ef79b8b76273"},"outputs":[{"name":"stdout","output_type":"stream","text":["Empty DataFrame\n","Columns: [TransactionID, CustomerID, TransactionAmount, TransactionDate, MerchantCategory, Age, Income, Occupation, Gender, CampaignID, CampaignDate, CampaignResponse]\n","Index: []\n","       TransactionID  CustomerID  TransactionAmount TransactionDate  \\\n","2674             546          58          93.652764      2023-06-30   \n","2675             546          58          93.652764      2023-06-30   \n","2676             546          58          93.652764      2023-06-30   \n","2677             546          58          93.652764      2023-06-30   \n","2678             546          58          93.652764      2023-06-30   \n","...              ...         ...                ...             ...   \n","43418           8948        1000         129.415168      2046-07-01   \n","43419           8948        1000         129.415168      2046-07-01   \n","43420           8948        1000         129.415168      2046-07-01   \n","43421           8948        1000         129.415168      2046-07-01   \n","43422           8948        1000         129.415168      2046-07-01   \n","\n","      MerchantCategory  Age  Income Occupation Gender  CampaignID  \\\n","2674       electronics   49  106634   Engineer   Male         248   \n","2675       electronics   49  106634   Engineer   Male         249   \n","2676       electronics   49  106634   Engineer   Male         250   \n","2677       electronics   49  106634   Engineer   Male         251   \n","2678       electronics   49  106634   Engineer   Male         252   \n","...                ...  ...     ...        ...    ...         ...   \n","43418         clothing   43  126803   Engineer   Male        4221   \n","43419         clothing   43  126803   Engineer   Male        4222   \n","43420         clothing   43  126803   Engineer   Male        4223   \n","43421         clothing   43  126803   Engineer   Male        4224   \n","43422         clothing   43  126803   Engineer   Male        4225   \n","\n","      CampaignDate  CampaignResponse  \n","2674    2022-09-05                 0  \n","2675    2022-09-06                 1  \n","2676    2022-09-07                 1  \n","2677    2022-09-08                 1  \n","2678    2022-09-09                 1  \n","...            ...               ...  \n","43418   2033-07-22                 1  \n","43419   2033-07-23                 1  \n","43420   2033-07-24                 1  \n","43421   2033-07-25                 1  \n","43422   2033-07-26                 1  \n","\n","[40749 rows x 12 columns]\n"]}],"source":["# Identify negative transaction amounts\n","negative_transactions = data[data['TransactionAmount'] < 0]\n","\n","# Print negative transactions\n","print(negative_transactions)\n","\n","# Identify transactions in the future\n","future_transactions = data[data['TransactionDate'] > pd.Timestamp.today()]\n","\n","# Print future transactions\n","print(future_transactions)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":193,"status":"ok","timestamp":1687979325432,"user":{"displayName":"Zhuchen Han (Shawn)","userId":"13195238100708308958"},"user_tz":240},"id":"8Ffngph10_9a","outputId":"64aa1b7d-09a4-40f1-9f5c-e66f9eb79d09"},"outputs":[{"name":"stdout","output_type":"stream","text":["Empty DataFrame\n","Columns: [TransactionID, CustomerID, TransactionAmount, TransactionDate, MerchantCategory, Age, Income, Occupation, Gender, CampaignID, CampaignDate, CampaignResponse]\n","Index: []\n","Empty DataFrame\n","Columns: [TransactionID, CustomerID, TransactionAmount, TransactionDate, MerchantCategory, Age, Income, Occupation, Gender, CampaignID, CampaignDate, CampaignResponse]\n","Index: []\n"]}],"source":["# Remove anomalies\n","data = data[data['TransactionAmount'] >= 0]\n","data = data[data['TransactionDate'] <= pd.Timestamp.today()]\n","\n","# Verify the removal\n","print(data[data['TransactionAmount'] < 0])\n","print(data[data['TransactionDate'] > pd.Timestamp.today()])\n"]},{"cell_type":"markdown","metadata":{"id":"EDXGna793FQU"},"source":["# Feature Engineering\n","**Q3** Using this combined dataset, how would you create a feature that encapsulates the change in a customer's spending habits after a successful marketing campaign interaction?\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"am0a6aJKryQd"},"outputs":[],"source":["# Convert dates to datetime format\n","data['TransactionDate'] = pd.to_datetime(data['TransactionDate'])\n","data['CampaignDate'] = pd.to_datetime(data['CampaignDate'])\n","\n","# Calculate pre and post campaign average transaction amounts for each campaign\n","pre_campaign_avg = data.loc[data['TransactionDate'] < data['CampaignDate']].groupby(['CustomerID', 'CampaignID'])['TransactionAmount'].mean()\n","post_campaign_avg = data.loc[data['TransactionDate'] > data['CampaignDate']].groupby(['CustomerID', 'CampaignID'])['TransactionAmount'].mean()\n","\n","# Compute difference\n","spending_change = post_campaign_avg - pre_campaign_avg\n","\n","# Merge back to original data\n","data = pd.merge(data, spending_change.rename('SpendingChange'), how='left', on=['CustomerID', 'CampaignID'])\n","\n"]},{"cell_type":"markdown","metadata":{"id":"skYCnKcssbZM"},"source":["**Q4** Can you devise a way to quantify a customer's responsiveness to our marketing campaigns? This might consider not just whether the customer responded, but how quickly they responded and how their behavior changed post-campaign.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bd2jOxiArywm"},"outputs":[],"source":["# Calculate time to next transaction after each campaign\n","data['TimeToNextTransaction'] = data.sort_values('TransactionDate').groupby(['CustomerID', 'CampaignID'])['TransactionDate'].diff().dt.days\n","# Some customers might not have a transaction after a campaign, fill NA values with a large number\n","data['TimeToNextTransaction'].fillna(999, inplace=True)\n","df = data.sort_values('TransactionDate').groupby(['CustomerID', 'CampaignID'])['TransactionDate']\n"]},{"cell_type":"markdown","metadata":{"id":"Iy3ttUW0smIj"},"source":["**Q5** How would you engineer a feature that represents the trend in a customer's income? Consider how you might capture changes in income over time, given that income might be related to a customer's transaction behavior."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HeHx7zw6soLy"},"outputs":[],"source":["# Compute trend in transaction amounts\n","data['TransactionTrend'] = data.sort_values('TransactionDate').groupby('CustomerID')['TransactionAmount'].pct_change()\n","\n"]},{"cell_type":"markdown","metadata":{"id":"bgTOR2XkDLcA"},"source":["# Modeling Metric & Model Selection\n","\n","**Q6** When evaluating a model's performance, why might accuracy not be the best metric here? What other metrics would you consider and why?\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":241,"status":"ok","timestamp":1687554858474,"user":{"displayName":"Corey Zhu","userId":"10558358170675623815"},"user_tz":240},"id":"UiSBPs77_mYY","outputId":"f0c67135-0dad-47d7-9382-36a079501970"},"outputs":[{"name":"stdout","output_type":"stream","text":["Precision: 0.5555555555555556\n","Recall: 0.7386363636363636\n","F1 Score: 0.6341463414634146\n","ROC AUC: 0.5738636363636364\n"]}],"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n","\n","# Load the data\n","# We'll assume that data is a pandas DataFrame loaded with your data\n","# And that \"CampaignSuccess\" is the target variable\n","\n","# Define the feature matrix X and the target y\n","X = data[['TransactionAmount', 'Age', 'Income', 'Occupation', 'Gender',  'TimeToNextTransaction']]\n","X = pd.get_dummies(X, columns=['Occupation', 'Gender'])\n","y = data['CampaignResponse']\n","\n","# Split the data into training and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Initialize the model\n","model = LogisticRegression()\n","\n","# Fit the model\n","model.fit(X_train, y_train)\n","\n","# Make predictions\n","y_pred = model.predict(X_test)\n","\n","# Calculate metrics\n","precision = precision_score(y_test, y_pred)\n","recall = recall_score(y_test, y_pred)\n","f1 = f1_score(y_test, y_pred)\n","roc_auc = roc_auc_score(y_test, y_pred)\n","\n","# Print the metrics\n","print(f\"Precision: {precision}\")\n","print(f\"Recall: {recall}\")\n","print(f\"F1 Score: {f1}\")\n","print(f\"ROC AUC: {roc_auc}\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"64dX-sOVDXX3"},"source":["**Q7** Explain how you would handle class imbalance in this prediction problem. How does class imbalance impact the choice of models and evaluation metrics?\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1687554918253,"user":{"displayName":"Corey Zhu","userId":"10558358170675623815"},"user_tz":240},"id":"SibexwnYDjZg","outputId":"bd8c7755-ba73-487e-e83b-2bc28a0a07a7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Precision: 0.563573883161512\n","Recall: 0.6212121212121212\n","F1 Score: 0.590990990990991\n","ROC AUC: 0.5700757575757576\n"]}],"source":["from sklearn.linear_model import LogisticRegression\n","\n","# Assume X is the feature matrix and y are the labels\n","# X = ...\n","# y = ...\n","\n","model = LogisticRegression(class_weight='balanced')\n","# Fit the model\n","model.fit(X_train, y_train)\n","\n","# Get predictions\n","y_pred = model.predict(X_test)\n","\n","precision = precision_score(y_test, y_pred)\n","recall = recall_score(y_test, y_pred)\n","f1 = f1_score(y_test, y_pred)\n","roc_auc = roc_auc_score(y_test, y_pred)\n","\n","# Print the metrics\n","print(f\"Precision: {precision}\")\n","print(f\"Recall: {recall}\")\n","print(f\"F1 Score: {f1}\")\n","print(f\"ROC AUC: {roc_auc}\")\n"]},{"cell_type":"markdown","metadata":{"id":"RO5BJhx4DrWB"},"source":["**Q8** How would you approach the problem if the model's performance is significantly different on the validation set than on the training set? What steps would you take to ensure your model is not overfitting?"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":258,"status":"ok","timestamp":1687554935627,"user":{"displayName":"Corey Zhu","userId":"10558358170675623815"},"user_tz":240},"id":"xTCeNKXnDw64","outputId":"e9daaf30-424f-4cbf-ca76-07574e3985a4"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cross-validated ROC AUC: 0.587368567675048\n"]}],"source":["from sklearn.model_selection import cross_val_score\n","\n","scores = cross_val_score(model, X, y, cv=5, scoring='roc_auc')\n","\n","print(f\"Cross-validated ROC AUC: {np.mean(scores)}\")\n"]},{"cell_type":"markdown","metadata":{"id":"5H_3ObzBEXG8"},"source":["# Business Insight\n","**Q9** After applying your model to the unified dataset, can you determine if there are any demographic groups that our campaigns are particularly effective or ineffective with? How might this information be useful for optimizing future campaigns?\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":957},"executionInfo":{"elapsed":895,"status":"ok","timestamp":1687555087353,"user":{"displayName":"Corey Zhu","userId":"10558358170675623815"},"user_tz":240},"id":"-g6OSM7fEZBp","outputId":"071af063-c76d-47a3-92b7-99a64665aefb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Occupation\n","Artist            0.343008\n","Data Scientist    0.728997\n","Doctor            0.563177\n","Engineer          0.462299\n","Teacher           0.538188\n","Name: CampaignResponse, dtype: float64\n"]}],"source":["# Group data by occupation and calculate average response\n","occupation_effectiveness = data.groupby('Occupation')['CampaignResponse'].mean()\n","\n","# Print the results\n","print(occupation_effectiveness)\n"]},{"cell_type":"markdown","metadata":{"id":"QfPIqLmBEOwF"},"source":["**Q10** If a competitor has successfully increased their customer engagement with a similar marketing strategy, how would you incorporate this information into your analysis to further optimize our own strategy?\n"]},{"cell_type":"markdown","metadata":{"id":"SzZu_wmLEU7H"},"source":["**Q11** How would you estimate the potential increase in revenue that could result from implementing your recommendations?\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QaYGC_cGkSGE","outputId":"12c50c79-bebd-4b61-eec8-b6c826b1bcb7"},"outputs":[{"name":"stdout","output_type":"stream","text":["13326.64553183677\n"]}],"source":["# Calculate the existing average transaction amount and response rate\n","avg_transaction_amount = data['TransactionAmount'].mean()\n","avg_response_rate = data['CampaignResponse'].mean()\n","\n","# Assume an estimated increase in response rate based on the recommendations\n","estimated_increase = 0.05 # This is just an example\n","\n","# Calculate the potential increase in revenue\n","potential_revenue_increase = avg_transaction_amount * estimated_increase * len(data)\n","\n","print(potential_revenue_increase)"]},{"cell_type":"markdown","metadata":{"id":"U12DKdSOKoh0"},"source":["**Q12** What are the potential risks of implementing your recommendations and how would you mitigate these risks? How would you track and measure the success of implementing your recommendations?"]}],"metadata":{"colab":{"provenance":[{"file_id":"1dui3P217XYcvKZfyJOajAJwUnEK7KIfX","timestamp":1687546737504}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"}},"nbformat":4,"nbformat_minor":0}